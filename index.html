<!DOCTYPE html>
<html>
<font face="Verdana" size = "2.5">
<head>

<style type="text/css">
A:link { COLOR: #0903A5; TEXT-DECORATION: none; font-weight: normal }
A:visited { COLOR: #0903A5; TEXT-DECORATION: none; font-weight: normal }
A:active { COLOR: #0903A5; TEXT-DECORATION: none }
A:hover { COLOR: #C80537; TEXT-DECORATION: none; font-weight: none }
img {
  margin-top: -20px;
  margin-bottom: 0px;
}
h1 {
  margin-top: 15px;
  margin-bottom: 15px;
}
h2 {
  margin-top: 10px;
  margin-bottom: 10px;
}
h2 + ul {
  margin-top: -5px;
  margin-bottom: 0px;
}
h2 + ol {
  margin-top: 0px;
  margin-bottom: 20px;
}
h3 + ol {
  margin-top: -10px;
  margin-bottom: -10px;
}
hr {
    display: block;
    height: 1px;
    border: 0;
    border-top: 1px solid #ccc;
    margin: 1em 0;
    padding: 0;
}
</style>

<title>Paul Liang, CMU</title>

</head>

<body>

<img src="photo.jpeg" width="160" height="160" style="float: left; PADDING-TOP: 20px; PADDING-RIGHT: 10px; PADDING-BOTTOM: 0px"/>

<img src="cmu.jpg" width="110" height="110" style="float: right; PADDING-TOP: 30px"/>
<img src="scs.jpg" width="110" height="110" style="float: right; PADDING-TOP: 30px"/>
<img src="mllti.jpg" width="300" height="120" style="float: right; PADDING-TOP: 45px"/>

<h1>Paul Pu Liang</h1>
Email: pliang(at)cs.cmu.edu<br/>
Office: Gates and Hillman Center 8011<br/>
5000 Forbes Avenue, Pittsburgh, PA 15213<br/>
<a href="http://multicomp.cs.cmu.edu/">Multicomp Lab</a>, <a href="https://www.lti.cs.cmu.edu/">Language Technologies Institute</a>, <a href="https://www.cs.cmu.edu/">School of Computer Science</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a><br/>

<br/>

<a href="cv_03_2021.pdf">[CV]</a>

<a href="https://scholar.google.com/citations?hl=en&user=pKf5LtQAAAAJ"> <img src="gscholar.jpg" width="24" height="24" style="margin-bottom:-7px;PADDING-LEFT:5px;PADDING-RIGHT:5px"></a>

<a href="https://www.linkedin.com/in/paulpuliang/"> <img src="linkedin.png" width="20" height="20" style="margin-bottom:-5px;PADDING-LEFT:5px;PADDING-RIGHT:5px"></a> 

<a href="https://github.com/pliang279"> <img src="github.png" width="30" height="30" style="margin-bottom:-10px">@pliang279</a>

<a href="https://twitter.com/pliang279/"> <img src="twitter.png" width="30" height="30" style="margin-bottom:-10px">@pliang279</a>

<a href="https://www.instagram.com/lpwinniethepu/"> <img src="instagram.png" width="22" height="22" style="margin-bottom:-6px;PADDING-LEFT:5px;PADDING-TOP: 10px"> @lpwinniethepu</a>

<br/>
<hr/>
I am a third-year Ph.D. student in the <a href="http://www.ml.cmu.edu/">Machine Learning Department</a> at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, advised by <a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a> and <a href="https://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov</a>. My long-term research goal is to build socially intelligent embodied agents with the ability to perceive and engage in multimodal human communication. As steps towards this goal, my research focuses on 1) the fundamentals of multimodal learning, specifically the representation, translation, fusion, and alignment of heterogeneous data sources, 2) human-centered language, vision, speech, robotics, and healthcare applications, as well as 3) the real-world deployment of socially intelligent agents by improving fairness, robustness, and interpretability in real-world applications. My research has been recognized by paper awards at the <a href="https://arxiv.org/abs/2001.01523">NeurIPS 2019 workshop on federated learning</a> and <a href="https://arxiv.org/abs/1802.00924">ICMI 2017</a>. I regularly organize the workshop on multimodal learning (<a href="http://multicomp.cs.cmu.edu/naacl2021multimodalworkshop/">NAACL 2021</a>, <a href="http://multicomp.cs.cmu.edu/acl2020multimodalworkshop/">ACL 2020</a>, and <a href="http://multicomp.cs.cmu.edu/acl2018multimodalchallenge/">ACL 2018</a>) and have also participated as an organizer for the <a href="https://tensorworkshop.github.io/NeurIPS2020/index.html">workshop on tensor networks at NeurIPS 2020</a> and a workflow chair for <a href="https://icml.cc/Conferences/2019/">ICML 2019</a>.
<br/>
<br/>
Previously, I received an M.S. in Machine Learning and a B.S. with University Honors in Computer Science from CMU, where I am grateful for the mentorship of <a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a>, <a href="https://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov</a>, <a href="http://www.cnbc.cmu.edu/~tai/">Tai Sing Lee</a>, <a href="http://www.stat.cmu.edu/~ryantibs/index.html">Ryan Tibshirani</a>, and <a href="http://www.cs.cmu.edu/~roni/">Roni Rosenfeld</a>. I have also been fortunate to spend time at <a href="https://ai.facebook.com/">Facebook AI Research</a>, <a href="https://www.nvidia.com/en-us/research/">Nvidia AI</a>, <a href="https://ai.google/research/">Google Research</a>, and <a href="https://aip.riken.jp/">RIKEN Artificial Intelligence Project</a>.

<br/>
<br/>
<a href="#News">[News]</a> <a href="#Education">[Education]</a> <a href="#Experience">[Experience]</a> <a href="#Publications">[Publications]</a> <a href="#Honors">[Honors]</a> <a href="#Teaching">[Teaching]</a> <a href="#Students">[Students]</a> <a href="#Talks">[Talks]</a> <a href="#Activities">[Activities]</a>

<h2 id="News">News</h2>

<ul style="list-style-type:disc; line-height:140%">

  <li><font color="#DC143C">02/2021</font>: Check out our new ICLR paper on <a href="https://arxiv.org/abs/2003.08197">learning efficient sparse embeddings for text, users, and recommendation sytems</a>!



  <li><font color="#DC143C">12/2020</font>: Fully recorded <a href="https://www.youtube.com/channel/UCqlHIJTGYhiwQpNuPU5e2gg">lecture videos</a> and <a href="https://cmu-multicomp-lab.github.io/mmml-course/fall2020/">course content</a> for 11-777 Advanced Multimodal Machine Learning, Fall 2020.</li>
  <li><font color="#DC143C">10/2020</font>: Check out the <a href="https://blog.ml.cmu.edu/">CMU Machine Learning Blog</a> - new research and educational content every few weeks on ML research going on at CMU!</li>
  <li><font color="#DC143C">08/2020</font>: I will be the head TA for 11-777 Advanced Multimodal Machine Learning in Fall 2020. Follow the class <a href="https://cmu-multicomp-lab.github.io/mmml-course/fall2020/">here!</a></li>
  <li><font color="#DC143C">06/2020</font>: Check out our ACL paper on <a href="https://arxiv.org/abs/2007.08100">mitigating bias in sentence representations</a> and the <a href="https://www.aclweb.org/anthology/volumes/2020.challengehml-1/">proceedings</a> from our ACL workshop on multimodal language.
  <li><font color="#DC143C">02/2020</font>: New preprints on <a href="https://arxiv.org/abs/2003.08197">sparse representation learning</a>, <a href="https://arxiv.org/abs/2002.06541">robust learning from noisy labels</a>, and <a href="https://arxiv.org/abs/2003.03212">diverse trajectory forecasting</a>.
  <li>12/2019: We are organizing the <a href="http://multicomp.cs.cmu.edu/acl2020multimodalworkshop/">Second Grand Challenge and Workshop on Human Multimodal Language</a> at ACL 2020! Consider submitting your work!</li>
  <li>09/2019: <a href="https://arxiv.org/abs/1907.00208">Learning to abstain under uncertainty with portfolio theory</a> accepted to NeurIPS 2019.
  <li>08/2019: I will be the head TA for <a href="https://piazza.com/cmu/fall2019/11777/resources">11-777 Advanced Multimodal Machine Learning</a> in Fall 2019, with new content on multimodal RL, alignment, language grounding, and interpretable learning!</li>
  <li>06/2019: I am compiling a <a href="https://github.com/pliang279/awesome-multimodal-ml/">reading list for multimodal ML</a> containing papers, software, workshops, tutorials, and courses! It spans various modalities (language, vision, speech, video, touch) and applications (QA, dialog, RL, reasoning, grounding, navigation, affective computing, healthcare, robotics). Links to code and data are included. I'll be updating regularly, if there's anything I missed, please let me know.
  <li>06/2019: New preprints on <a href="https://arxiv.org/abs/2001.01523">fair federated learning via local models</a>, <a href="https://arxiv.org/abs/1907.00208">learning to abstain under uncertainty</a>, and <a href="https://arxiv.org/abs/1903.00840">generative models for incomplete data</a>.
  <li>05/2019: 2 papers accepted at ACL 2019 on learning from <a href="https://arxiv.org/abs/1907.01011">imperfect</a> and <a href="https://arxiv.org/abs/1906.00295">unaligned</a> multimodal time series data.
  <li>02/2019: We will present 2 papers at NAACL and CVPR 2019: <a href="https://arxiv.org/abs/1906.02125">strong baselines for multimodal learning</a> and a <a href="https://www.thesocialiq.com">new QA dataset on comprehending social interactions</a>.</li>
  <li>01/2019: I will be a TA for <a href="https://sailinglab.github.io/pgm-spring-2019/">10-708 Probabilistic Graphical Models</a> in Spring 2019, with new content on deep generative models, RL, and probabilistic programming!</li>
  <li>01/2019: Excited to be a workflow chair for <a href="https://icml.cc/Conferences/2019/">ICML 2019</a>!</li>
  <li>12/2018: "<a href="https://arxiv.org/abs/1806.06176">Learning Factorized Multimodal Representations</a>" to appear at ICLR 2019.</li>
  <li>08/2018: I will be a TA for <a href="http://www.cs.cmu.edu/~10715-f18/">10-715 Advanced Introduction to Machine Learning</a> in Fall 2018.</li>
  <li>05/2018: I completed my <a href="papers/dap2018_mosei_paper.pdf">Master's Data Analysis Project research </a> and received the 1st runner-up award.</li>
  <li>04/2018: 3 papers presented at ACL 2018 main conference and workshops: <a href="http://aclweb.org/anthology/P18-1208">CMU-MOSEI dataset</a>, <a href="https://arxiv.org/abs/1806.00064">low-rank fusion</a>, and <a href="https://arxiv.org/abs/1807.03915">seq2seq2sentiment</a>.</li>
  <li>01/2018: We are organizing the <a href="http://multicomp.cs.cmu.edu/acl2018multimodalchallenge/">First Grand Challenge and Workshop on Human Multimodal Language</a> at ACL 2018.</li>
  <li>11/2017: Our paper on <a href="https://arxiv.org/abs/1802.00924">gated multimodal fusion</a> won the honorable mention award at ICMI 2017!</li>
</ul>

<h2 id="Education">Education</h2>

<ul style="list-style-type:disc; line-height:140%">
  <li><b>Carnegie Mellon University</b>, Pittsburgh, PA, USA. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Aug 2018 - Present</li>
  Ph.D. in Machine Learning (GPA: 4.23/4.00)<br/>
  Advisors: <a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a> and <a href="https://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov</a>

  <li><b>Carnegie Mellon University</b>, Pittsburgh, PA, USA. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Aug 2017 - May 2018</li>
  M.S. in Machine Learning (GPA: 4.24/4.00)<br/>
  Advisors: <a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a> and <a href="https://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov</a><br/>
  Thesis: Computational Modeling of Human Multimodal Language

  <li><b>Carnegie Mellon University</b>, Pittsburgh, PA, USA. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Aug 2014 - May 2017</li>
  B.S. with University Honors in Computer Science (GPA: 3.87/4.00)<br/>
  Minor in Neural Computation
</ul>

<h2 id="Experience">Experience</h2>

<ul style="list-style-type:disc; line-height:140%">

  <li><b>Google DeepMind</b>, London, UK. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;June 2021 - Oct 2021</li>
  Research Intern<br/>
  Advisors: Dani Yogatama, Aida Nematzadeh, and Phil Blunsom

  <li><b>Facebook AI Research</b>, New York, NY, USA. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;May 2020 - Aug 2020</li>
  Research Intern<br/>
  Advisors: <a href="http://bamos.github.io/">Brandon Amos</a>, <a href="https://rockt.github.io/">Tim Rockt&auml;schel</a>, and <a href="https://www.egrefen.com/">Ed Grefenstette</a>

  <li><b>Nvidia AI</b>, Santa Clara, CA, USA and Toronto, Canada. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Feb 2020 - May 2020</li>
  Research Intern<br/>
  Advisors: <a href="http://ai.stanford.edu/~yukez/">Yuke Zhu</a>, <a href="http://tensorlab.cms.caltech.edu/users/anima/">Anima Anandkumar</a>, and <a href="https://www.cs.utoronto.ca/~fidler/">Sanja Fidler</a>

  <li><b>Google Research</b>, Mountain View, CA, USA and Pittsburgh, PA, USA. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;May 2019 - Nov 2019</li>
  Research Intern<br/>
  Advisors: <a href="http://www.manzil.ml/">Manzil Zaheer</a>, <a href="https://ai.google/research/people/YuanWang">Yuan Wang</a>, and <a href="https://ai.google/research/people/AmrAhmed">Amr Ahmed</a>

  <li><b>RIKEN Artificial Intelligence Project</b>, Tokyo, Japan and Kyoto, Japan. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Dec 2018 - Jan 2019</li>
  Visiting Researcher<br/>
  Advisors: <a href="https://riken-yamada.github.io/">Makoto Yamada</a>, <a href="https://qibinzhao.github.io/">Qibin Zhao</a>, and <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/">Masashi Sugiyama</a>
</ul>

<h2 id="Publications">Publications</h2>

(* denotes joint first-authors)

<h3>2021</h3>

<ol reversed=true type="1" start="32" style="line-height:140%">

  <li><b>StylePTB: A Compositional Benchmark for Fine-grained Controllable Text Style Transfer</b></li>
  Yiwei Lyu*, Paul Pu Liang*, Hai Pham*, Eduard Hovy, Barnab&aacute;s P&oacute;czos, Ruslan Salakhutdinov, Louis-Philippe Morency<br/>
  NAACL 2021<br/>
  [arXiv] <a href="https://github.com/lvyiwei1/StylePTB">[code]</a>

  <li><b>Ask & Explore: Grounded Question Answering for Curiosity-Driven Exploration</b></li>
  Jivat Neet, Yiding Jiang, Paul Pu Liang<br/>
  ICLR 2021 Workshop on Embodied Multimodal Learning<br/>
  [arXiv] [code]

  <li><b>Anchor &amp; Transform: Learning Sparse Embeddings for Large Vocabularies</b></li>
  Paul Pu Liang, Manzil Zaheer, Yuan Wang, Amr Ahmed<br/>
  ICLR 2021<br/>
  <a href="https://arxiv.org/abs/2003.08197">[arXiv]</a> <a href="https://github.com/pliang279/sparse_discrete">[code]</a>

  <li><b>Understanding the Tradeoffs in Client-Side Privacy for Speech Recognition</b></li>
  Peter Wu, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency<br/>
  preprint<br/>
  <a href="https://arxiv.org/abs/2101.08919">[arXiv]</a>

  <li><b>An Investigation of how Label Smoothing Affects Generalization</b></li>
  Blair Chen, Liu Ziyin, Zihao Wang, Paul Pu Liang<br/>
  preprint<br/>
  <a href="https://arxiv.org/abs/2010.12648">[arXiv]</a>
</ol>


<h3>2020</h3>

<ol reversed=true type="1" start="27" style="line-height:140%">

  <li><b>Cross-Modal Generalization: Learning in Low Resource Modalities via Meta-Alignment</b></li>
  Paul Pu Liang, Peter Wu, Liu Ziyin, Louis-Philippe Morency, Ruslan Salakhutdinov<br/>
  NeurIPS 2020 Workshop on Meta Learning<br/>
  <a href="https://arxiv.org/abs/2012.02813">[arXiv]</a> <a href="https://github.com/peter-yh-wu/xmodal">[code]</a>

  <li><b>Multimodal Privacy-preserving Mood Prediction from Mobile Data: A Preliminary Study</b></li>
  Terrance Liu*, Paul Pu Liang*, Michal Muszynski, Ryo Ishii, David Brent, Randy Auerbach, Nicholas Allen, Louis-Philippe Morency<br/>
  NeurIPS 2020 Workshop on Machine Learning for Mobile Health<br/>
  <a href="https://arxiv.org/abs/2012.02359">[arXiv]</a>

  <li><b>MOSEAS: A Multimodal Language Dataset for Spanish, Portuguese, German and French</b></li>
  Amir Zadeh, Yansheng Cao, Simon Hessner, Paul Pu Liang, Soujanya Poria, Louis-Philippe Morency<br/>
  EMNLP 2020<br/>
  <a href="https://www.aclweb.org/anthology/2020.emnlp-main.141.pdf">[paper]</a>

  <li><b>Diverse and Admissible Trajectory Prediction through Multimodal Context Understanding</b></li>
  Seong Hyeon Park, Gyubok Lee, Manoj Bhat, Jimin Seo, Minseok Kang, Jonathan Francis, Ashwin R. Jadhav, Paul Pu Liang, Louis-Philippe Morency<br/>
  ECCV 2020 <br/>
  CVPR 2020 Argoverse competition <font color="#DC143C">(honorable mention award)</font><br/>
  <a href="https://arxiv.org/abs/2003.03212">[arXiv]</a> <a href="https://github.com/kami93/CMU-DATF">[code]</a>

  <li><b>Towards Debiasing Sentence Representations</b></li>
  Paul Pu Liang, Irene Li, Emily Zheng, Yao Chong Lim, Ruslan Salakhutdinov, Louis-Philippe Morency<br/>
  ACL 2020<br/>
  <a href="https://arxiv.org/abs/2007.08100">[arXiv]</a> <a href="https://github.com/pliang279/sent_debias">[code]</a>

  <li><b>On Emergent Communication in Competitive Multi-Agent Teams</b></li>
  Paul Pu Liang, Jeffrey Chen, Ruslan Salakhutdinov, Louis-Philippe Morency, Satwik Kottur<br/>
  AAMAS 2020 <font color="#DC143C">(oral)</font><br/>
  NeurIPS 2019 Workshop on Emergent Communication<br/>
  <a href="https://arxiv.org/abs/2003.01848">[arXiv]</a> <a href="https://github.com/pliang279/Competitive-Emergent-Communication">[code]</a> <a href="slides/aamas2020_communication_slides.pdf">[slides]</a>

  <li><b>Empirical and Theoretical Studies of Multimodal Co-learning</b></li>
  Amir Zadeh, Paul Pu Liang, Louis-Philippe Morency<br/>
  Elsevier Information Fusion 2020<br/>
  <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253520303006">[arXiv]</a>
</ol>

<h3>2019</h3>

<ol reversed=true type="1" start="20" style="line-height:140%">

  <li><b>Think Locally, Act Globally: Federated Learning with Local and Global Representations</b></li>
  Paul Pu Liang*, Terrance Liu*, Liu Ziyin, Nicholas Allen, Randy Auerbach, David Brent, Ruslan Salakhutdinov, Louis-Philippe Morency<br/>
  NeurIPS 2019 Workshop on Federated Learning <font color="#DC143C">(oral, distinguished student paper award)</font><br/>
  <a href="https://arxiv.org/abs/2001.01523">[arXiv]</a> <a href="https://github.com/pliang279/LG-FedAvg">[code]</a>

  <li><b>Deep Gamblers: Learning to Abstain with Portfolio Theory</b></li>
  Liu Ziyin, Zhikang Wang, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency, Masahito Ueda<br/>
  NeurIPS 2019<br/>
  <a href="https://arxiv.org/abs/1907.00208">[arXiv]</a> <a href="https://github.com/Z-T-WANG/NIPS2019DeepGamblers">[code]</a> <a href="posters/neurips2019_gamblers_poster.pdf">[poster]</a>

  <li><b>Learning Representations from Imperfect Time Series Data via Tensor Rank Regularization</b></li>
  Paul Pu Liang*, Zhun Liu*, Yao-Hung Hubert Tsai, Qibin Zhao, Ruslan Salakhutdinov, Louis-Philippe Morency<br/>
  ACL 2019<br/>
  <a href="https://arxiv.org/abs/1907.01011">[arXiv]</a> <a href="posters/acl2019_tensor_poster.pdf">[poster]</a>

  <li><b>Multimodal Transformer for Unaligned Multimodal Language Sequences</b></li>
  Yao-Hung Hubert Tsai, Shaojie Bai, Paul Pu Liang, Zico Kolter, Louis-Philippe Morency, Ruslan Salakhutdinov<br/>
  ACL 2019<br/>
  <a href="https://arxiv.org/abs/1906.00295">[arXiv]</a> <a href="https://github.com/yaohungt/Multimodal-Transformer">[code]</a>

  <li><b>Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence</b></li>
  Amir Zadeh, Michael Chan, Paul Pu Liang, Edmund Tong, Louis-Philippe Morency<br/>
  CVPR 2019 <font color="#DC143C">(oral)</font><br/>
  <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.pdf">[paper]</a> <a href="https://www.thesocialiq.com">[code]</a> <a href="posters/cvpr2019_socialiq_poster.pdf">[poster]</a>

  <li><b>Strong and Simple Baselines for Multimodal Utterance Embeddings</b></li>
  Paul Pu Liang*, Yao Chong Lim*, Yao-Hung Hubert Tsai, Ruslan Salakhutdinov, Louis-Philippe Morency<br/>
  NAACL 2019 <font color="#DC143C">(oral)</font><br/>
  <a href="https://arxiv.org/abs/1906.02125">[arXiv]</a> <a href="https://github.com/yaochie/multimodal-baselines">[code]</a> <a href="slides/naacl2019_baselines_slides.pdf">[slides]</a>

  <li><b>Learning Factorized Multimodal Representations</b></li>
  Yao-Hung Hubert Tsai*, Paul Pu Liang*, Amir Zadeh, Louis-Philippe Morency, Ruslan Salakhutdinov<br/>
  ICLR 2019<br/>
  NeurIPS 2018 Workshop on Bayesian Deep Learning<br/>
  <a href="https://arxiv.org/abs/1806.06176">[arXiv]</a> <a href="https://github.com/pliang279/factorized">[code]</a> <a href="posters/iclr2019_factorized_poster.pdf">[poster]</a>

  <li> <b>Found in Translation: Learning Robust Joint Representations by Cyclic Translations Between Modalities</b></li>
  Hai Pham*, Paul Pu Liang*, Thomas Manzini, Louis-Philippe Morency, Barnab&aacute;s P&oacute;czos<br/>
  AAAI 2019<br/>
  NeurIPS 2018 Workshop on Interpretability and Robustness in Audio, Speech and Language <font color="#DC143C">(oral)</font><br/>
  <a href="https://arxiv.org/abs/1812.07809">[arXiv]</a> <a href="https://github.com/hainow/MCTN">[code]</a> <a href="slides/aaai2019_translations_slides.pdf">[slides]</a> <a href="posters/aaai2019_translations_poster.pdf">[poster]</a>

  <li><b>Words can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors</b></li>
  Yansen Wang, Ying Shen, Zhun Liu, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency<br/>
  AAAI 2019<br/>
  <a href="https://arxiv.org/abs/1811.09362">[arXiv]</a> <a href="https://github.com/victorywys/RAVEN">[code]</a> <a href="slides/aaai2019_variations_slides.pdf">[slides]</a> <a href="posters/aaai2019_variations_poster.pdf">[poster]</a>
</ol>

<h3>2018</h3>

<ol reversed=true type="1" start="11" style="line-height:140%">

  <li><b>Computational Modeling of Human Multimodal Language: The MOSEI Dataset and Interpretable Dynamic Fusion</b></li>
  Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency<br/>
  Master's Thesis, CMU Machine Learning Data Analysis Project 2018 <font color="#DC143C">(first runner-up award)</font><br/>
  <a href="papers/dap2018_mosei.pdf">[paper]</a> <a href="slides/dap2018_mosei_slides.pdf">[slides]</a> <a href="posters/dap2018_mosei_poster.pdf">[poster]</a>

  <li><b>Multimodal Language Analysis with Recurrent Multistage Fusion</b></li>
  Paul Pu Liang, Ziyin Liu, Amir Zadeh, Louis-Philippe Morency<br/>
  EMNLP 2018 <font color="#DC143C">(oral)</font><br/>
  NeurIPS 2018 Workshop on Modeling and Decision-making in the Spatiotemporal Domain <font color="#DC143C">(oral)</font><br/>
  <a href="https://arxiv.org/abs/1808.03920">[arXiv]</a> <a href="slides/emnlp2018_multistage_slides.pdf">[slides]</a> <a href="posters/nips2018ws_multistage_poster.pdf">[poster]</a>
  
  <li><b>Multimodal Local-Global Ranking Fusion for Emotion Recognition</b></li>
  Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency<br/>
  <font color="black">ICMI 2018</font><br/>
  <a href="https://arxiv.org/abs/1809.04931">[arXiv]</a> <a href="posters/icmi2018_ranking_poster.pdf">[poster]</a>

  <li><b>An Empirical Evaluation of Sketched SVD and its Application to Leverage Score Ordering</b></li>
  Hui Han Chin, Paul Pu Liang<br/>
  ACML 2018<br/>
  <a href="https://arxiv.org/abs/1812.07903">[arXiv]</a> <a href="slides/acml2018_sketching_slides.pdf">[slides]</a> <a href="posters/acml2018_sketching_poster.pdf">[poster]</a>
  
  <li><b>Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph</b></li>
  Amir Zadeh, Paul Pu Liang, Jonathan Vanbriesen, Soujanya Poria, Edmund Tong, Erik Cambria, Minghai Chen, Louis-Philippe Morency<br/>
  ACL 2018 <font color="#DC143C">(oral)</font><br/>
  <a href="http://aclweb.org/anthology/P18-1208">[arXiv]</a> <a href="https://github.com/A2Zadeh/CMU-MultimodalSDK">[code]</a> <a href="slides/acl2018_mosei_slides.pdf">[slides]</a>
  
  <li><b>Efficient Low-rank Multimodal Fusion with Modality-Specific Factors</b></li>
  Zhun Liu, Ying Shen, Varun Lakshminarasimhan, Paul Pu Liang, Amir Zadeh, Louis-Philippe Morency<br/>
  ACL 2018 <font color="#DC143C">(oral)</font><br/>
  <a href="https://arxiv.org/abs/1806.00064">[arXiv]</a> <a href="https://github.com/Justin1904/Low-rank-Multimodal-Fusion">[code]</a> <a href="slides/acl2018_lowrank_slides.pdf">[slides]</a>
  
  <li><b>Multi-attention Recurrent Network for Human Communication Comprehension</b></li>
  Amir Zadeh, Paul Pu Liang, Soujanya Poria, Prateek Vij, Erik Cambria, Louis-Philippe Morency<br/>
  AAAI 2018 <font color="#DC143C">(oral)</font><br/>
  <a href="https://arxiv.org/abs/1802.00923">[arXiv]</a> <a href="https://github.com/A2Zadeh/MARN">[code]</a> <a href="slides/aaai2018_marn_slides.pdf">[slides]</a>
  
  <li><b>Memory Fusion Network for Multi-view Sequential Learning</b></li>
  Amir Zadeh, Paul Pu Liang, Navonil Mazumder, Soujanya Poria, Erik Cambria, Louis-Philippe Morency<br/>
  AAAI 2018 <font color="#DC143C">(oral)</font><br/>
  <a href="https://arxiv.org/abs/1802.00927">[arXiv]</a> <a href="https://github.com/pliang279/MFN">[code]</a> <a href="slides/aaai2018_mfn_slides.pdf">[slides]</a>
</ol> 

<h3>2017</h3>

<ol reversed=true type="1" start="3" style="line-height:140%">
  <li><b>Multimodal Sentiment Analysis with Word-level Fusion and Reinforcement Learning</b></li>
  Minghai Chen*, Sen Wang*, Paul Pu Liang*, Tadas Baltru&scaron;aitis, Amir Zadeh, Louis-Philippe Morency<br/>
  ICMI 2017 <font color="#DC143C">(oral, honorable mention award)</font><br/>
  <a href="https://arxiv.org/abs/1802.00924">[arXiv]</a> <a href="https://drive.google.com/drive/u/0/folders/1NxyFuogyzNFoCH0Zi5aIXUGYKGuSY9TY">[code]</a> <a href="slides/icmi2017_gme_slides.pdf">[slides]</a>
</ol>

<h3>Organized Workshop Proceedings</h3>

<ol reversed=true type="1" style="line-height:140%">
  <li><b>Proceedings of the Second Grand Challenge and Workshop on Human Multimodal Language (Challenge-HML)</b></li>
  ACL 2020 Workshop Proceedings<br/>
  <a href="https://www.aclweb.org/anthology/volumes/2020.challengehml-1/">[proceedings]</a> <a href="http://multicomp.cs.cmu.edu/acl2020multimodalworkshop/">[website]</a>

  <li><b>Proceedings of the First Grand Challenge and Workshop on Human Multimodal Language (Challenge-HML)</b></li>
  ACL 2018 Workshop Proceedings<br/>
  <a href="https://www.aclweb.org/anthology/volumes/W18-33/">[proceedings]</a> <a href="http://multicomp.cs.cmu.edu/acl2018multimodalchallenge/">[website]</a> <a href="slides/acl2018ws_introduction_slides.pdf">[introduction]</a> <a href="slides/acl2018ws_datasets_slides.pdf">[datasets]</a> <a href="slides/acl2018ws_results_slides.pdf">[results]</a>
</ol>

<h2 id="Honors">Honors</h2>

<ul style="list-style-type:disc; line-height:140%">
  <li>CMU Graduate Research Fellowship: 2018-2023</li>
  <li>MIT Sandbox Innovation Program Funding Recipient: 2021</li>
  <li>CVPR 2020 Argoverse Competition Honorable Mention: 2020</li>
  <li>NeurIPS 2019 Workshop on Federated Learning Distinguished Student Paper: 2019</li>
  <li>NeurIPS 2019 Travel Award and Reviewer Award: 2019</li>
  <li>CVPR 2019 Oral Presentation (top 5.6% of submissions): 2019</li>
  <li>CMU Teaching Assistant Award: 2019</li>
  <li>Princeton University Gordon Wu Fellowship (declined): 2018</li>
  <li>NSF Graduate Research Fellowship Honorable Mention: 2018</li>
  <li>CMU Machine Learning Department Data Analysis Project First Runner-up: 2018</li>
  <li>ICMI 2017 Best Paper Honorable Mention (top 1.3% of submissions): 2017</li>
  <li>CMU School of Computer Science University Honors: 2017</li>
  <li>CMU School of Computer Science Dean's List: 2015, 2016, 2017</li>
  <li>Harvard University Hacking Eating Tracking Hackathon Judge's Choice Award: 2015</li>
</ul>

<h2 id="Teaching">Teaching</h2>

<ul style="list-style-type:disc; line-height:140%">
  <li>Head TA & Lecturer: <a href="https://cmu-multicomp-lab.github.io/mmml-course/fall2020/">11-777 Multimodal Machine Learning</a>, Fall 2020, CMU. Instructor: <a href="http://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a></li>
  <li>Head TA & Lecturer: <a href="https://piazza.com/cmu/fall2019/11777/resources">11-777 Multimodal Machine Learning</a>, Fall 2019, CMU. Instructor: <a href="http://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a></li>
  <li>TA: <a href="https://sailinglab.github.io/pgm-spring-2019/">10-708 Probabilistic Graphical Models</a>, Spring 2019, CMU. Instructor: <a href="http://www.cs.cmu.edu/~epxing/">Eric Xing</a></li>
  <li>TA: <a href="http://www.cs.cmu.edu/~10715-f18/">10-715 Advanced Introduction to Machine Learning</a>, Fall 2018, CMU. Instructor: <a href="https://www.cs.cmu.edu/~ninamf/">Maria-Florina Balcan</a></li>
  <li>TA: <a href="http://www.cs.cmu.edu/~roni/10601/">10-601 Introduction to Machine Learning</a>, Fall 2016, CMU. Instructor: <a href="https://www.cs.cmu.edu/~roni/">Roni Rosenfeld</a></li>
  <li>TA: <a href="https://www.cs.cmu.edu/~213/">15-213/18-213/15-513 Introduction to Computer Systems</a>, Summer 2016, CMU. Instructor: <a href="https://www.cs.cmu.edu/~bpr/">Brian Railing</a></li>
</ul>

<h2 id="Talks">Academic Talks</h2>

<ul style="list-style-type:disc">

  <li><b>Towards Real-World Social AI</b></li>
  Adobe Research, Online, Jan 2021<br/>
  CMU, Online, Oct 2020<br/>
  [slides]

  <li><b>Towards Debiasing Sentence Representations</b></li>
  ACL 2020, Online, July 2020<br/>
  <a href="https://docs.google.com/presentation/d/10HDn5LjABRcGocelKbhn7VRsL6GY69tj-DnRXrRBAcU/edit?usp=sharing">[slides]</a>

  <li><b>On Emergent Communication in Competitive Multi-Agent Teams</b></li>
  AAMAS 2020, Online, May 2020<br/>
  <a href="https://drive.google.com/file/d/1Jqtaa5seRmnuuCYYOUhqsQxhQaxzQxl1/view?usp=sharing">[slides]</a>

  <li><b>Think Locally, Act Globally: Federated Learning with Local and Global Representations</b></li>
  NeurIPS 2019 Workshop on Federated Learning, Vancouver, Canada, Dec 2019<br/>
  <a href="https://docs.google.com/presentation/d/1FILIzRxkSTmWa-8dit6EN64SRKhNB1eYu9FAtyog59I/edit?usp=sharing">[slides]</a>

  <li><b>Learning Sparse Representations of Discrete Objects</b></li>
  ICLR 2021, Online, May 2021<br/>  
  Google Research, Mountain View, CA, USA, Aug 2019<br/>
  <a href="https://docs.google.com/presentation/d/1JI6t_g9JDtTJgGdiNOuWNXaLxdN9g52TiS7gbnpjk9M/edit?usp=sharing">[slides]</a>

  <li><b>Computational Modeling of Human Multimodal Language</b></li>
  Google Research, Mountain View, CA, USA, July 2019<br/>
  RIKEN Artificial Intelligence Project Machine Learning Seminar, Tokyo, Japan, Jan 2019<br/>
  RIKEN Artificial Intelligence Project Machine Learning Seminar, Kyoto, Japan, Dec 2018<br/>
  ACL 2018, Melbourne, Australia, July 2018<br/>
  CMU Machine Learning Department Data Analysis Project Presentation, Pittsburgh, PA, USA, Apr 2018<br/>
  <a href="slides/2018_hml_slides.pdf">[slides]</a>

  <li><b>Learning Robust Joint Representations by Cyclic Translations Between Modalities</b></li>
  AAAI 2019, Honolulu, HI, USA, Feb 2019<br/>
  NeurIPS 2018 Workshop on Interpretability and Robustness, Montreal, Canada, Dec 2018<br/>
  <a href="slides/nips2018ws_translations_slides.pdf">[slides]</a>

  <li><b>Multimodal Language Analysis with Recurrent Multistage Fusion</b></li>
  NeurIPS 2018 Workshop on Spatiotemporal Modeling, Montreal, Canada, Dec 2018<br/>
  EMNLP 2018, Brussels, Belgium, Nov 2018<br/>
  <a href="slides/emnlp2018_multistage_slides.pdf">[slides]</a>
  
  <li><b>Advances in Multimodal Datasets</b></li>
  First Workshop on Human Multimodal Language at ACL 2018, Melbourne, Australia, July 2018<br/>
  <a href="slides/acl2018ws_datasets_slides.pdf">[slides]</a>
  
  <li><b>Multi-attention Recurrent Network for Human Communication Comprehension</b></li>
  AAAI 2018, New Orleans, LA, USA, Feb 2018<br/>
  <a href="slides/aaai2018_marn_slides.pdf">[slides]</a>
  
</ul>

<h2 id="Activities">Professional Activities</h2>

<ul style="list-style-type:disc; line-height:140%">
  <li>Workflow Chair: <a href="https://icml.cc/Conferences/2019/">ICML 2019</a></li>
  <li>Session Chair: <a href="https://aaai.org/Conferences/AAAI-19/">AAAI 2019</a></li>
  <li>General Chair: <a href="http://multicomp.cs.cmu.edu/naacl2021multimodalworkshop/">NAACL 2021 Third Workshop on Multimodal Artificial Intelligence</a>
  <li>General Chair: <a href="https://tensorworkshop.github.io/NeurIPS2020/index.html">NeurIPS 2020 First Workshop on Quantum Tensor Networks in Machine Learning</a>
  <li>General Chair: <a href="http://multicomp.cs.cmu.edu/acl2020multimodalworkshop/">ACL 2020 Second Grand Challenge and Workshop on Human Multimodal Language</a>
  <li>General Chair: <a href="http://multicomp.cs.cmu.edu/acl2018multimodalchallenge/">ACL 2018 First Grand Challenge and Workshop on Human Multimodal Language</a></li>
  <li>Senior PC Member: IJCAI</li>
  <li>Conference Program Committee: NeurIPS, ICML, ICLR, ACL, EMNLP, NAACL, EACL, COLING, IJCNLP, AACL, CVPR, ICCV, ECCV, WACV, ACCV, AAAI, IJCAI, AISTATS, UAI, CHI, ICMI, FG, ACML, ML4H, CHIL, ACM Multimedia, Interspeech</li>
  <li>Workshop Program Committee: NeurIPS workshop on Meta Learning, NeurIPS workshop on Machine Learning for Health, ICLR workshop on Embodied Multimodal Learning, ICLR workshop on Never-ending RL, ICLR workshop on Enormous Language Models, ACL workshop on Multimodal Language, EMNLP workshop on NLP Open Source Software, EMNLP workshop on NLP Beyond Text, NAACL workshop on Trustworthy NLP, NAACL workshop on Multimodal AI, IJCAI workshop on Federated Learning, WWW workshop on NLP Beyond Text</li>
  <li>Journal Reviewer: IEEE Transactions on Affective Computing, IEEE Transactions on Multimedia, IEEE Transactions on Cybernetics, IEEE Computational Intelligence Magazine, IEEE Signal Processing Letters, Elsevier Information Fusion, Elsevier Computer Speech and Language, Machine Learning</li>
  <li><a href="http://cmu.aiplus.club/">CMU AI+</a> Committee: 2019, 2020</li>
  <li><a href="https://blog.ml.cmu.edu/">CMU Machine Learning Blog</a> Editorial Board: 2019, 2020</li>
  <li>CMU AI Undergraduate Research Mentor: 2018, 2019, 2020</li>
  <li>CMU Machine Learning Department PhD Admissions Committee: 2018, 2019, 2020</li>
  <li>CMU Machine Learning Department Masters Admissions Committee: 2017, 2018</li>
  <li>CMU Singapore Students Association Co-President: 2015</li>
</ul>

<br/>
I have an Erd&#337;s number of 3 (Paul Erd&#337;s &rarr; Giuseppe Melfi &rarr; Erik Cambria &rarr; Paul Pu Liang).<br/>
This page has been accessed at least <a href="http://stuff.mit.edu/doc/counter-howto.html"><img src="http://stuff.mit.edu/cgi/counter/pliang" alt="several" style="PADDING-TOP: 20px"></a> times since Feb 8, 2018.

</body>
</font>
</html>
